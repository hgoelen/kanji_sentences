{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necesseray libraries\n",
    "\n",
    "!pip install ankipandas\n",
    "!pip install genanki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from ankipandas import Collection\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import genanki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the location of your Anki collection; we'll next open our collection\n",
    "\n",
    "collection_location = ''\n",
    "col = Collection(collection_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the deck with the Heisig lessons. Change the name if it has a different one in your collection\n",
    "\n",
    "kanji_deck = 'Remembering the Kanji 1, 6th edition (2200 kanji)'\n",
    "\n",
    "# Notes that belong to the kanji deck\n",
    "\n",
    "kanji_notes = col.cards[col.cards.cdeck==].nid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the deck with sample sentences. Change the name to whichever deck you need\n",
    "\n",
    "vocab_deck = 'Core 2k/6k Optimized Japanese Vocabulary with Sound Part 01'\n",
    "\n",
    "# Notes that belong to the sentence deck\n",
    "\n",
    "vocab_notes = col.cards[col.cards.cdeck==vocab_deck].nid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the fields of the sentence notes\n",
    "\n",
    "vocab_fields = col.notes[col.notes.index.isin(vocab_notes)]['nflds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this line, you can see what fields exist within a note. You can add '[0]' to the line below to see the first field, \n",
    "# '[1]' for the second etc. to see what's in a specific field and which number you need to extract it. (Python is zero-indexed,\n",
    "# meaning the first field is given number 0 etc.) Remember the numbers of the fields you want, you'll need them in the cell\n",
    "# below.\n",
    "\n",
    "vocab_fields.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we make a list of lists with all the fields that we'll need. As you can see, I am extracting three fields, which\n",
    "# correspond to the sentence with furigana marking, the translation and a reference to an audio file. Note that the numbers \n",
    "# 0, 10 and 12 refer to the positions of the fields for a note; you can type 'vocab_fields.values[0][0]' as in the cell above\n",
    "# to see what it is you're extracting.\n",
    "# I am also replacing the html-markings, though this done very basically. Edit the code to add more fields to your likings, \n",
    "# or remove the replace if you don't need it. You can use 'vocab_data[0]' to get a sense of the data you have compiled.\n",
    "\n",
    "vocab_data = []\n",
    "for note in vocab_fields:\n",
    "    selection = [note[8].replace('<b>', '').replace('</b>', ''), note[10].replace('<b>', '').replace('</b>', ''), note[12]]\n",
    "    vocab_data.append(selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I turn our data into a pandas dataframe. As you can see, I add three column names, because I have extracted three fields.\n",
    "# The number of column names should correspond to the number of fields you extracted in the cell above this one and they should\n",
    "# be in the right order as well.\n",
    "\n",
    "vocab_data = pd.DataFrame(vocab_data, columns=['Sentence', 'Translation', 'Audio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this we print a preview of our dataframe to see the results are to our likings\n",
    "\n",
    "vocab_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a function to extract all the kanji characters from a sentence. I use a regular expression to do this. The first line\n",
    "# references the column 'Sentence' which I named in the cell above; if you have given your Japanese sentence field a different\n",
    "# name, you should also change it here.\n",
    "\n",
    "def extract_kanji(row):\n",
    "    sentence = row.Sentence\n",
    "    kanji = set(re.findall(r'[㐀-䶵一-鿋豈-頻]', sentence))\n",
    "    return kanji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell we apply the function we defined above and add the result as a new column to our data frame, 'Kanji'.\n",
    "\n",
    "vocab_data['Kanji'] = vocab_data.apply(extract_kanji, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview our dataframe again to see it makes sense\n",
    "\n",
    "vocab_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel to what we did for our sentences, now we first extract the fields from our kanji deck, collect the kanji and the\n",
    "# Heisig lesson number into a list of lists and then turn it into a dataframe. Feel free to seperate these three lines of code\n",
    "# into seperate cells if you want it to be more clear or if you need to adjust it to your deck.\n",
    "\n",
    "kanji_fields = col.notes[col.notes.index.isin(kanji_notes)].nflds.values\n",
    "kanji_data = [[k[0], int(k[5])] for k in kanji_fields]\n",
    "kanji_data = pd.DataFrame(kanji_data, columns = ['Kanji', 'Lesson'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview our kanji data\n",
    "\n",
    "kanji_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to add the starting lesson to our sentence dataframe.\n",
    "\n",
    "def starting_lesson(row):\n",
    "    \n",
    "    # Read the kanji from our sentence dataframe. If you named your field differently, you need to adjust the name below too.\n",
    "    \n",
    "    kanji = row.Kanji\n",
    "    \n",
    "    # If there were no kanji in the sentence, return 0, meaning you can start learning this sentence without any kanji.\n",
    "    \n",
    "    if len(kanji) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Filter our kanji dataframe to just those characters used in the sentence.\n",
    "    \n",
    "    kanji_selection = kanji_data[kanji_data.Kanji.isin(kanji)]\n",
    "    \n",
    "    # If there are any kanji in this filtered dataframe, return the highest lesson number. If not, return 9999, meaning this\n",
    "    # sentence has kanji characters not covered in Heisig's book.\n",
    "    \n",
    "    if kanji_selection.shape[0] > 0:\n",
    "        return kanji_selection.Lesson.max()\n",
    "    else:\n",
    "        return 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function defined above\n",
    "\n",
    "vocab_data['Lesson_number'] = vocab_data.apply(starting_lesson, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just a graph so you can see how many sentences you can learn already\n",
    "\n",
    "grouping = vocab_data.groupby('Lesson_number').Sentence.nunique().to_frame().cumsum()\n",
    "grouping.plot(figsize=(15,12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview our data\n",
    "\n",
    "vocab_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deck title, name and model name for the new deck we will create.\n",
    "\n",
    "anki_deck_title = \"Selection 2k\"\n",
    "anki_model_name = 'Selection 2k'\n",
    "anki_deck_name = 'Selection 2k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model id\n",
    "\n",
    "model_id = random.randrange(1 << 30, 1 << 31)\n",
    "\n",
    "# Style of our cards; feel free to change to your liking\n",
    "\n",
    "style = \"\"\"\n",
    ".card {\n",
    " font-family: arial;\n",
    " font-size: 20px;\n",
    " text-align: center;\n",
    " color: black;\n",
    " background-color: white;\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Layout of our cards, again feel free to change. qfmt refers to the front.\n",
    "\n",
    "anki_model = genanki.Model(\n",
    "    model_id,\n",
    "    anki_model_name,\n",
    "    fields=[{\"name\": \"sentence\"}, {\"name\": \"translation\"}, {\"name\": \"heisig_lesson\"}, {\"name\": \"audio\"}],\n",
    "    templates=[\n",
    "        {\n",
    "            \"name\": \"Card 1\",\n",
    "            \"qfmt\": '<span style=\"font-size: 20px; \">{{translation}}</span>',\n",
    "            \"afmt\": '<span style=\"font-family: ＭＳ ゴシック; \">{{furigana:sentence}}</span><br><br>{{audio}}</p>',\n",
    "        }\n",
    "    ],\n",
    "    css=style,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of anki notes from our sentence dataframe. Again, mind the column names should overlap with how you defined\n",
    "# them above.\n",
    "\n",
    "anki_notes = []\n",
    "\n",
    "for index, row in vocab_data.iterrows():\n",
    "    sentence = row.Sentence\n",
    "    translation = row.Translation\n",
    "    audio = row.Audio\n",
    "    lesson_number = row.Lesson_number\n",
    "    anki_note = genanki.Note(\n",
    "        model=anki_model,\n",
    "        fields=[sentence, translation, str(lesson_number), audio],\n",
    "    )\n",
    "    anki_notes.append(anki_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anki_deck = genanki.Deck(model_id, anki_deck_title)\n",
    "anki_package = genanki.Package(anki_deck)\n",
    "\n",
    "# Add flashcards to the deck\n",
    "for anki_note in anki_notes:\n",
    "    anki_deck.add_note(anki_note)\n",
    "\n",
    "# Save the deck to a file\n",
    "file_location = ''\n",
    "anki_package.write_to_file(file_location)\n",
    "\n",
    "print(\"Created deck with {} flashcards\".format(len(anki_deck.notes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
